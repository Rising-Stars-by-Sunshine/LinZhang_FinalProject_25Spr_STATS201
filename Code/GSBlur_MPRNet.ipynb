{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77f7e658-f1d5-4335-8a4e-7a9961be5cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lpips\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/zhanglin/MPRNet/Deblurring\") # Path to where your MPRNet.py file is stored\n",
    "from Deblurring.MPRNet import MPRNet # Make sure you have cloned and set up the MPRNet repository\n",
    "\n",
    "# Set device (GPU/CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce429f40-d80d-4e7b-adf6-a543bbf6efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing and Dataset Definition\n",
    "class BlurredImageDataset(Dataset):\n",
    "    def __init__(self, input_dir, target_dir, transform=None):\n",
    "        self.input_dir = input_dir\n",
    "        self.target_dir = target_dir\n",
    "        self.transform = transform\n",
    "        self.input_files = sorted(os.listdir(input_dir))\n",
    "        self.target_files = sorted(os.listdir(target_dir))\n",
    "        \n",
    "        assert len(self.input_files) == len(self.target_files), \"Mismatch between input and target images!\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_image_path = os.path.join(self.input_dir, self.input_files[idx])\n",
    "        target_image_path = os.path.join(self.target_dir, self.target_files[idx])\n",
    "        \n",
    "        input_image = Image.open(input_image_path).convert('RGB')\n",
    "        target_image = Image.open(target_image_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            input_image = self.transform(input_image)\n",
    "            target_image = self.transform(target_image)\n",
    "        \n",
    "        return input_image, target_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0b425fc-40ab-4949-9b16-c2edc3fab77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation techniques\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((96, 96)),\n",
    "    transforms.RandomRotation(15),  # Random rotation for data augmentation\n",
    "    transforms.RandomHorizontalFlip(),  # Random horizontal flip\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "218c6f9c-8f9b-4ea5-9f67-2e664695d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to GS-Blur dataset\n",
    "input_dir_gsblur = '/Users/zhanglin/Documents/dku/2024-2025/session3/STATS 201/reflection/week2/mini/input_noise'  # Folder containing blurry images\n",
    "target_dir_gsblur = '/Users/zhanglin/Documents/dku/2024-2025/session3/STATS 201/reflection/week2/mini/target'      # Folder containing clean images\n",
    "\n",
    "# Load GS-Blur dataset\n",
    "gsblur_dataset = BlurredImageDataset(input_dir_gsblur, target_dir_gsblur, transform=transform)\n",
    "\n",
    "# Split the dataset into train and validation\n",
    "train_dataset_gsblur, val_dataset_gsblur = train_test_split(gsblur_dataset, test_size=0.2, random_state=42)\n",
    "train_loader_gsblur = DataLoader(train_dataset_gsblur, batch_size=16, shuffle=True, num_workers=2)\n",
    "val_loader_gsblur = DataLoader(val_dataset_gsblur, batch_size=10, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3698aba1-9414-4407-8e72-2b575ad475f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize MPRNet model (without passing num_channels or num_features)\n",
    "model = MPRNet().to(device)  \n",
    "\n",
    "# Initialize Loss Function (e.g., MSELoss for deblurring)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Initialize Optimizer (Adam optimizer)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Learning Rate Scheduler (optional)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c1d8d078-a9e1-4627-9a7c-c9cff6e95818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MPRNet on GS-Blur dataset...\n",
      "Epoch [1/10], Step [10/50], Loss: 0.1503\n",
      "Epoch [1/10], Step [20/50], Loss: 0.1339\n",
      "Epoch [1/10], Step [30/50], Loss: 0.1789\n",
      "Epoch [1/10], Step [40/50], Loss: 0.1295\n",
      "Epoch [1/10], Step [50/50], Loss: 0.1349\n",
      "Epoch [1/10], Average Loss: 0.1540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(2178) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(2179) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [10/50], Loss: 0.1553\n",
      "Epoch [2/10], Step [20/50], Loss: 0.1539\n",
      "Epoch [2/10], Step [30/50], Loss: 0.1455\n",
      "Epoch [2/10], Step [40/50], Loss: 0.1139\n",
      "Epoch [2/10], Step [50/50], Loss: 0.1403\n",
      "Epoch [2/10], Average Loss: 0.1476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(3200) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(3202) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [10/50], Loss: 0.1342\n",
      "Epoch [3/10], Step [20/50], Loss: 0.1435\n",
      "Epoch [3/10], Step [30/50], Loss: 0.1293\n",
      "Epoch [3/10], Step [40/50], Loss: 0.1631\n",
      "Epoch [3/10], Step [50/50], Loss: 0.1904\n",
      "Epoch [3/10], Average Loss: 0.1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(4292) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(4293) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [10/50], Loss: 0.1874\n",
      "Epoch [4/10], Step [20/50], Loss: 0.1170\n",
      "Epoch [4/10], Step [30/50], Loss: 0.1104\n",
      "Epoch [4/10], Step [40/50], Loss: 0.1548\n",
      "Epoch [4/10], Step [50/50], Loss: 0.1775\n",
      "Epoch [4/10], Average Loss: 0.1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(5102) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(5103) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [10/50], Loss: 0.1564\n",
      "Epoch [5/10], Step [20/50], Loss: 0.1304\n",
      "Epoch [5/10], Step [30/50], Loss: 0.1640\n",
      "Epoch [5/10], Step [40/50], Loss: 0.1438\n",
      "Epoch [5/10], Step [50/50], Loss: 0.1465\n",
      "Epoch [5/10], Average Loss: 0.1430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(6461) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(6462) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [10/50], Loss: 0.1323\n",
      "Epoch [6/10], Step [20/50], Loss: 0.1753\n",
      "Epoch [6/10], Step [30/50], Loss: 0.1378\n",
      "Epoch [6/10], Step [40/50], Loss: 0.1277\n",
      "Epoch [6/10], Step [50/50], Loss: 0.1361\n",
      "Epoch [6/10], Average Loss: 0.1410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(7665) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(7666) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [10/50], Loss: 0.1315\n",
      "Epoch [7/10], Step [20/50], Loss: 0.1286\n",
      "Epoch [7/10], Step [30/50], Loss: 0.1312\n",
      "Epoch [7/10], Step [40/50], Loss: 0.1582\n",
      "Epoch [7/10], Step [50/50], Loss: 0.1156\n",
      "Epoch [7/10], Average Loss: 0.1389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(8616) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(8617) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [10/50], Loss: 0.1417\n",
      "Epoch [8/10], Step [20/50], Loss: 0.1432\n",
      "Epoch [8/10], Step [30/50], Loss: 0.1286\n",
      "Epoch [8/10], Step [40/50], Loss: 0.1274\n",
      "Epoch [8/10], Step [50/50], Loss: 0.1266\n",
      "Epoch [8/10], Average Loss: 0.1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(9508) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(9511) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [10/50], Loss: 0.1293\n",
      "Epoch [9/10], Step [20/50], Loss: 0.1462\n",
      "Epoch [9/10], Step [30/50], Loss: 0.1312\n",
      "Epoch [9/10], Step [40/50], Loss: 0.1521\n",
      "Epoch [9/10], Step [50/50], Loss: 0.1641\n",
      "Epoch [9/10], Average Loss: 0.1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(10392) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(10393) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [10/50], Loss: 0.1533\n",
      "Epoch [10/10], Step [20/50], Loss: 0.1303\n",
      "Epoch [10/10], Step [30/50], Loss: 0.1265\n",
      "Epoch [10/10], Step [40/50], Loss: 0.1105\n",
      "Epoch [10/10], Step [50/50], Loss: 0.1511\n",
      "Epoch [10/10], Average Loss: 0.1373\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, optimizer, criterion, scheduler, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)  # MPRNet returns a list of tensors\n",
    "            \n",
    "            # Extract the final output (last tensor in the list)\n",
    "            final_output = outputs[-1]  # Assuming the last tensor is the final output\n",
    "            \n",
    "            # Ensure final_output and targets have the same shape\n",
    "            if final_output.shape != targets.shape:\n",
    "                raise ValueError(f\"Shape mismatch: final_output {final_output.shape}, targets {targets.shape}\")\n",
    "            \n",
    "            # Compute loss using the final output\n",
    "            loss = criterion(final_output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # Step learning rate scheduler\n",
    "        scheduler.step(epoch_loss / len(train_loader))\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Average Loss: {epoch_loss / len(train_loader):.4f}')\n",
    "\n",
    "# Train MPRNet on GS-Blur dataset\n",
    "print(\"Training MPRNet on GS-Blur dataset...\")\n",
    "train_model(model, train_loader_gsblur, optimizer, criterion, scheduler, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9d6be929-9ac8-4f4b-8d64-86d2359af578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MPRNet on GS-Blur dataset...\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /opt/anaconda3/lib/python3.12/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "GS-Blur Dataset -> Mean PSNR: 8.8505, Mean SSIM: 0.2413, Mean LPIPS: 0.6165\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    lpips_values = []\n",
    "    lpips_model = lpips.LPIPS(net='vgg').to(device)  # Make sure LPIPS is initialized here\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)  # MPRNet returns a list of tensors\n",
    "\n",
    "            # Extract the final output (last tensor in the list)\n",
    "            final_output = outputs[-1]  # Assuming the last tensor is the final output\n",
    "\n",
    "            # Normalize inputs and targets to [-1, 1] for LPIPS\n",
    "            inputs_lpips = (inputs - 0.5) / 0.5\n",
    "            targets_lpips = (targets - 0.5) / 0.5\n",
    "            outputs_lpips = (final_output - 0.5) / 0.5  # Normalize the final output\n",
    "\n",
    "            # PSNR\n",
    "            for i in range(inputs.shape[0]):\n",
    "                psnr_value = psnr(targets[i].cpu().numpy(), final_output[i].cpu().numpy(), data_range=1.0)\n",
    "                psnr_values.append(psnr_value)\n",
    "\n",
    "            # SSIM\n",
    "            for i in range(inputs.shape[0]):\n",
    "                if min(targets[i].shape[-2:]) >= 7:\n",
    "                    ssim_value = ssim(\n",
    "                        targets[i].cpu().numpy(), \n",
    "                        final_output[i].cpu().numpy(), \n",
    "                        win_size=3, \n",
    "                        channel_axis=-1, \n",
    "                        data_range=1.0\n",
    "                    )\n",
    "                else:\n",
    "                    ssim_value = 0  # or handle it differently\n",
    "                ssim_values.append(ssim_value)\n",
    "\n",
    "            # LPIPS\n",
    "            lpips_value = lpips_model(outputs_lpips, targets_lpips)  # Compute LPIPS\n",
    "            lpips_values.extend(lpips_value.squeeze().cpu().numpy())  # Flatten and append\n",
    "\n",
    "    mean_psnr = np.mean(psnr_values)\n",
    "    mean_ssim = np.mean(ssim_values)\n",
    "    mean_lpips = np.mean(lpips_values)\n",
    "\n",
    "    return mean_psnr, mean_ssim, mean_lpips\n",
    "\n",
    "# Evaluate MPRNet on GS-Blur dataset\n",
    "print(\"Evaluating MPRNet on GS-Blur dataset...\")\n",
    "mean_psnr_gsblur, mean_ssim_gsblur, mean_lpips_gsblur = evaluate_model(model, val_loader_gsblur)\n",
    "print(f'GS-Blur Dataset -> Mean PSNR: {mean_psnr_gsblur:.4f}, Mean SSIM: {mean_ssim_gsblur:.4f}, Mean LPIPS: {mean_lpips_gsblur:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e7ac08-2ca3-4c57-8645-bbebad817209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
